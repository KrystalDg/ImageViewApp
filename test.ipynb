{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image as pil\n",
    "from PIL import Image\n",
    "from pkg_resources import parse_version\n",
    "if parse_version(pil.__version__)>=parse_version('10.0.0'):\n",
    "    Image.ANTIALIAS=Image.LANCZOS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.config import Cfg\n",
    "\n",
    "def maximize_contrast(imgGrayscale):\n",
    "\t#Làm cho độ tương phản lớn nhất \n",
    "\theight, width = imgGrayscale.shape[:2]\n",
    "\t\n",
    "\timgTopHat = np.zeros((height, width, 1), np.uint8)\n",
    "\timgBlackHat = np.zeros((height, width, 1), np.uint8)\n",
    "\tstructuringElement = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)) #tạo bộ lọc kernel\n",
    "\t\n",
    "\timgTopHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_TOPHAT, structuringElement, iterations = 5) #nổi bật chi tiết sáng trong nền tối\n",
    "\t#cv2.imwrite(\"tophat.jpg\",imgTopHat)\n",
    "\timgBlackHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_BLACKHAT, structuringElement, iterations = 15) #Nổi bật chi tiết tối trong nền sáng\n",
    "\t#cv2.imwrite(\"blackhat.jpg\",imgBlackHat)\n",
    "\timgGrayscalePlusTopHat = cv2.add(imgGrayscale, imgTopHat) \n",
    "\timgGrayscalePlusTopHatMinusBlackHat = cv2.subtract(imgGrayscalePlusTopHat, imgBlackHat)\n",
    "\n",
    "\t#Kết quả cuối là ảnh đã tăng độ tương phản \n",
    "\treturn imgGrayscalePlusTopHatMinusBlackHat\n",
    "\n",
    "def remove_noise(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = maximize_contrast(img)\n",
    "\n",
    "    _, blackAndWhite = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((2,3),np.uint8)\n",
    "    blackAndWhite = cv2.dilate(blackAndWhite, np.ones((2,3),np.uint8), iterations=1)\n",
    "    blackAndWhite = cv2.erode(blackAndWhite, kernel, iterations=1)\n",
    "    blackAndWhite = cv2.dilate(blackAndWhite, np.ones((2,3),np.uint8), iterations=1)\n",
    "    blackAndWhite = cv2.erode(blackAndWhite, kernel, iterations=1)\n",
    "    blackAndWhite = cv2.dilate(blackAndWhite, np.ones((1,2),np.uint8), iterations=1)\n",
    "\n",
    "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(blackAndWhite, None, None, None, 8, cv2.CV_32S)\n",
    "    sizes = stats[1:, -1] #get CC_STAT_AREA component\n",
    "    img2 = np.zeros((labels.shape), np.uint8)\n",
    "\n",
    "    for i in range(0, nlabels - 1):\n",
    "        if sizes[i] >= 19:   #filter small dotted regions\n",
    "            img2[labels == i + 1] = 255\n",
    "\n",
    "    res = cv2.bitwise_not(img2)\n",
    "    kernel1 = np.ones((2,2),np.uint8)\n",
    "    res = cv2.morphologyEx(res, cv2.MORPH_OPEN, kernel1)\n",
    "\n",
    "    res = cv2.GaussianBlur(res,(3,3),2)\n",
    "\n",
    "    return res\n",
    "\n",
    "img = cv2.imread('img1.png')\n",
    "img = remove_noise(img)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image as pil\n",
    "from PIL import Image\n",
    "from pkg_resources import parse_version\n",
    "if parse_version(pil.__version__)>=parse_version('10.0.0'):\n",
    "    Image.ANTIALIAS=Image.LANCZOS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.config import Cfg\n",
    "\n",
    "def maximize_contrast(imgGrayscale):\n",
    "\t#Làm cho độ tương phản lớn nhất \n",
    "\theight, width = imgGrayscale.shape[:2]\n",
    "\t\n",
    "\timgTopHat = np.zeros((height, width, 1), np.uint8)\n",
    "\timgBlackHat = np.zeros((height, width, 1), np.uint8)\n",
    "\tstructuringElement = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)) #tạo bộ lọc kernel\n",
    "\t\n",
    "\timgTopHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_TOPHAT, structuringElement, iterations = 5) #nổi bật chi tiết sáng trong nền tối\n",
    "\t#cv2.imwrite(\"tophat.jpg\",imgTopHat)\n",
    "\timgBlackHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_BLACKHAT, structuringElement, iterations = 15) #Nổi bật chi tiết tối trong nền sáng\n",
    "\t#cv2.imwrite(\"blackhat.jpg\",imgBlackHat)\n",
    "\timgGrayscalePlusTopHat = cv2.add(imgGrayscale, imgTopHat) \n",
    "\timgGrayscalePlusTopHatMinusBlackHat = cv2.subtract(imgGrayscalePlusTopHat, imgBlackHat)\n",
    "\n",
    "\t#Kết quả cuối là ảnh đã tăng độ tương phản \n",
    "\treturn imgGrayscalePlusTopHatMinusBlackHat\n",
    "\n",
    "def remove_noise(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # img = maximize_contrast(img)\n",
    "\n",
    "    _, blackAndWhite = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    blackAndWhite = cv2.dilate(blackAndWhite, np.ones((2,1),np.uint8), iterations=1)\n",
    "    blackAndWhite = cv2.erode(blackAndWhite, np.ones((2,2),np.uint8), iterations=1)\n",
    "    blackAndWhite = cv2.dilate(blackAndWhite, np.ones((2,1),np.uint8), iterations=1)\n",
    "\n",
    "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(blackAndWhite, None, None, None, 8, cv2.CV_32S)\n",
    "    sizes = stats[1:, -1] #get CC_STAT_AREA component\n",
    "    img2 = np.zeros((labels.shape), np.uint8)\n",
    "\n",
    "    for i in range(0, nlabels - 1):\n",
    "        if sizes[i] >= 19:   #filter small dotted regions\n",
    "            img2[labels == i + 1] = 255\n",
    "\n",
    "    res = cv2.bitwise_not(img2)\n",
    "    kernel1 = np.ones((2,2),np.uint8)\n",
    "    res = cv2.morphologyEx(res, cv2.MORPH_OPEN, kernel1)\n",
    "\n",
    "    res = cv2.GaussianBlur(res,(3,3),2)\n",
    "\n",
    "    return res\n",
    "\n",
    "class OCRModel(object):\n",
    "    def __init__(self, weight_path=None):\n",
    "        if weight_path != None:\n",
    "            self.weight_path = weight_path\n",
    "        else:\n",
    "            self.weight_path = \"vietocr_model/weights/vgg_transformer_default.pth\"\n",
    "\n",
    "        # self.config = Cfg.load_config_from_name('vgg_transformer')\n",
    "        self.config = Cfg.load_config_from_file('vietocr_model/config.yml')\n",
    "        # self.config = Cfg.load_config_from_file('vietocr_model/config_vgg_seq2seq.yml')\n",
    "        self.config['weights'] = self.weight_path\n",
    "        self.config['cnn']['pretrained']=False\n",
    "        self.config['device'] = 'cpu'\n",
    "        self.config['predictor'].update({'beamsearch': True})\n",
    "\n",
    "        self.detector = Predictor(self.config)\n",
    "\n",
    "    def recognize(self, img):\n",
    "        s = self.detector.predict(Image.fromarray(img), return_prob=False)\n",
    "        return s\n",
    "\n",
    "\n",
    "\n",
    "ocr = OCRModel(\"vietocr_model/weights/transformerocr_custom.pth\")\n",
    "# ocr = OCRModel(\"vietocr_model/weights/vgg_seq2seq.pth\")\n",
    "# ocr = OCRModel()\n",
    "img = Image.open('img3.png')\n",
    "img = remove_noise(np.array(img))\n",
    "plt.imshow(img)\n",
    "s = ocr.recognize(np.array(img))\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "import editdistance\n",
    "\n",
    "\n",
    "def ocr_metrics(predicts, ground_truth, norm_accentuation=False, norm_punctuation=False):\n",
    "    \"\"\"Calculate Character Error Rate (CER), Word Error Rate (WER) and Sequence Error Rate (SER)\"\"\"\n",
    "\n",
    "    if len(predicts) == 0 or len(ground_truth) == 0:\n",
    "        return (1, 1, 1)\n",
    "\n",
    "    cer, wer, ser = [], [], []\n",
    "\n",
    "    for (pd, gt) in zip(predicts, ground_truth):\n",
    "\n",
    "        if norm_accentuation:\n",
    "            pd = unicodedata.normalize(\"NFKD\", pd).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n",
    "            gt = unicodedata.normalize(\"NFKD\", gt).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n",
    "\n",
    "        if norm_punctuation:\n",
    "            pd = pd.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "            gt = gt.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "        pd_cer, gt_cer = list(pd.lower()), list(gt.lower())\n",
    "        dist = editdistance.eval(pd_cer, gt_cer)\n",
    "        cer.append(dist / (max(len(pd_cer), len(gt_cer))))\n",
    "\n",
    "        pd_wer, gt_wer = pd.lower().split(), gt.lower().split()\n",
    "        dist = editdistance.eval(pd_wer, gt_wer)\n",
    "        wer.append(dist / (max(len(pd_wer), len(gt_wer))))\n",
    "\n",
    "        pd_ser, gt_ser = [pd], [gt]\n",
    "        dist = editdistance.eval(pd_ser, gt_ser)\n",
    "        ser.append(dist / (max(len(pd_ser), len(gt_ser))))\n",
    "\n",
    "    cer_f = sum(cer) / len(cer)\n",
    "    wer_f = sum(wer) / len(wer)\n",
    "    ser_f = sum(ser) / len(ser)\n",
    "\n",
    "    return (cer_f, wer_f, ser_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "RAW_FOLDER = pathlib.Path(\"/home/krystal/LearnSpace/LVTN/Data/Processing/data-extract/data0\").absolute()\n",
    "TEST_FOLDER = os.path.join(RAW_FOLDER, \"test_line\")\n",
    "TEST_JSON = os.path.join(RAW_FOLDER, \"test_line.json\")\n",
    "TEST_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# open these label jsons files\n",
    "with open(TEST_JSON, 'r', encoding='utf8') as f:\n",
    "    test_labels = json.load(f)\n",
    "# tesr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_filepath_label={}\n",
    "raw_data_path = pathlib.Path(os.path.join(TEST_FOLDER))\n",
    "for item in raw_data_path.glob('**/*.*'):\n",
    "    file_name=str(os.path.basename(item))\n",
    "    if (file_name != \"labels.json\"):\n",
    "        label = test_labels[file_name]\n",
    "        dict_filepath_label[str(item)]=label\n",
    "all_image_paths = list(dict_filepath_label.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig_txt = []\n",
    "pred = []\n",
    "for test_img_path in all_image_paths:\n",
    "    img = cv2.imread(test_img_path)\n",
    "    img = remove_noise(img)\n",
    "    s = ocr.recognize(img)\n",
    "    pred.append(s)\n",
    "    label = dict_filepath_label[test_img_path]\n",
    "    test_orig_txt.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = ocr_metrics( predicts=pred,\n",
    "                        ground_truth=test_orig_txt,\n",
    "                        norm_accentuation=False,\n",
    "                        norm_punctuation=False)\n",
    "\n",
    "e_corpus = \"\\n\".join([\n",
    "    \"Metrics:\",\n",
    "    \"Character Error Rate: {}\".format(evaluate[0]),\n",
    "    \"Word Error Rate:      {}\".format(evaluate[1]),\n",
    "    \"Sequence Error Rate:  {}\".format(evaluate[2]),\n",
    "])\n",
    "print(e_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
